{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditions for Linear Regression\n",
    "\n",
    "The conditions surrounding linear regression typically surround the residuals. Residuals are defined as:\n",
    "\n",
    "$$ \n",
    "Y - \\hat{Y}\n",
    "$$\n",
    "\n",
    "These are the deviations in the observed scores from the predicted scores from the linear regression. Recall, through least square estimation that these residauls will sum to 0, therefore, their mean would also be equal to 0. However, there are certain conditions about these residuals that are made for the linear regression model to have the inferences be appropriate. We'll talk more about what the implications for violating these conditions will have on the linear regression model, but first, the conditions. \n",
    "\n",
    "1. Approximately Normally distributed residuals\n",
    "2. Homogeneity of variance\n",
    "3. Uncorrelated residuals\n",
    "4. Error term is uncorrelated with the predictor attribute\n",
    "5. Linearity and additivity of the model. \n",
    "\n",
    "Each of these will be discussed in turn. \n",
    "\n",
    "Data conditions that are not directly testable: \n",
    "\n",
    "1. Validity\n",
    "2. Representativeness\n",
    "\n",
    "### Data\n",
    "The  data for this section of notes will explore data from the [Environmental Protection Agency on Air Quality](https://www.epa.gov/outdoor-air-quality-data) collected for the state of Iowa in 2021. The data are daily values for PM 2.5 particulates. The attributes included in the data are shown below with a short description.\n",
    "\n",
    "| Variable | Description | \n",
    "|:---------|:------------|\n",
    "| date      | Date of observation |\n",
    "| id | Site ID |\n",
    "| poc | Parameter Occurrence Code (POC) |\n",
    "| pm2.5 | Average daily pm 2.5 particulate value, in (ug/m3; micrograms per meter cubed) |\n",
    "| daily_aqi | Average air quality index |\n",
    "| site_name | Site Name |\n",
    "| aqs_parameter_desc | Text Description of Observation |\n",
    "| cbsa_code | Core Based Statistical Area (CBSA) ID |\n",
    "| cbsa_name | CBSA Name |\n",
    "| county | County in Iowa |\n",
    "| avg_wind | Average daily wind speed (in knots) | \n",
    "| max_wind | Maximum daily wind speed (in knots) | \n",
    "| max_wind_hours | Time of maximum daily wind speed |\n",
    "\n",
    "\n",
    "#### Guiding Question\n",
    "How is average daily wind speed related to the daily air quality index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(ggformula)\n",
    "library(mosaic)\n",
    "\n",
    "theme_set(theme_bw(base_size = 18))\n",
    "\n",
    "airquality <- readr::read_csv(\"https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/iowa_air_quality_2021.csv\")\n",
    "wind <- readr::read_csv(\"https://raw.githubusercontent.com/lebebr01/psqf_6243/main/data/daily_WIND_2021-iowa.csv\")\n",
    "\n",
    "airquality <- airquality |>\n",
    "   left_join(wind, by = c('cbsa_name', 'date')) |> \n",
    "   drop_na()\n",
    "\n",
    "air_lm <- lm(daily_aqi ~ avg_wind, data = airquality)\n",
    "coef(air_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The residuals can be saved with the `resid()` function. These can also be added to the original data, which are particularly helpful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(resid(air_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "airquality$residuals <- resid(air_lm)\n",
    "head(airquality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximately Normally distributed residuals\n",
    "\n",
    "The first assumption is that the residuals are at least approximately Normally distributed. This assumption is really only much of a concern when the sample size is small. If the sample size is larger, the Central Limit Thereom (CLT) states that the distribution of the statstics will be approximately normally distributed. The threshold for the CLT to be properly invoked is about 30. Larger then this, the residuals do not need to be approximately normally distributed. Even still, exploring the distribution of the residuals can still be helpful and can also be helpful to identify potential extreme values. \n",
    "\n",
    "This example will make use of the air quality data one more time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gf_density(~ residuals, data = airquality) |>\n",
    "  gf_labs(x = \"Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(airquality, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different QQ plots by distribution type\n",
    "\n",
    "This next section will generate some residuals that would fit certain types you may see in practice. These are meant as a way to give you some data from residuals that would be common in practice.\n",
    "\n",
    "\n",
    "#### Symmetric / Normally Distributed Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages('patchwork')\n",
    "library(patchwork)\n",
    "\n",
    "sim_resid <- data.frame(residuals = rnorm(500, 0, sd = 1))\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewed Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sim_resid <- data.frame(residuals = rchisq(500, df = 1) - 1)\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negatively Skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sim_resid <- data.frame(residuals = (rchisq(500, df = 1) - 1) * -1)\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heavy Tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sim_resid <- data.frame(residuals = (rt(500, df = 4)))\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sim_resid <- data.frame(residuals = (runif(500, min = -1, max = 1)))\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Floor Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sim_resid <- data.frame(residuals = (rnorm(500, mean = 0, sd = 1))) |> \n",
    "   mutate(residuals = ifelse(residuals < -1.5, -1.5, residuals))\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ceiling Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sim_resid <- data.frame(residuals = (rnorm(500, mean = 0, sd = 1))) |> \n",
    "   mutate(residuals = ifelse(residuals > 1.5, 1.5, residuals))\n",
    "\n",
    "dens <- gf_density(~ residuals, data = sim_resid) |>\n",
    "  gf_labs(x = \"Residuals\")\n",
    "\n",
    "qq_plot <- ggplot(sim_resid, aes(sample = residuals)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(linewidth = 2)\n",
    "\n",
    "dens + qq_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Residuals\n",
    "\n",
    "Standardized residuals can be another way to explore the residuals. These will now be standardized to have a variance of 1, similar to that of a Z-score. These can be computed as:\n",
    "\n",
    "$$ \n",
    "standardized\\ residuals = \\frac{\\epsilon_{i}}{SD_{\\epsilon}}\n",
    "$$\n",
    "\n",
    "Within R, these can be computed using the function `rstandard()`. Furthermore, these can be computed from another package called broom with the `augment()` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(rstandard(air_lm))\n",
    "\n",
    "library(broom)\n",
    "\n",
    "resid_diagnostics <- augment(air_lm)\n",
    "head(resid_diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gf_density(~ .std.resid, data = resid_diagnostics) |>\n",
    "  gf_labs(x = \"Standardized Residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(resid_diagnostics, aes(sample = .std.resid)) + \n",
    "  stat_qq(size = 5) + \n",
    "  stat_qq_line(size = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homogeneity of variance\n",
    "\n",
    "Homoegeneity of variance is an assumption that is of larger concern compared to normality of the residuals. Homoogeneity of variance is an assumption that states that the variance of the residuals are similar across the predicted or fitted values from the regression line. This assumption can be explored by looking at the residuals (standardized or raw residuals), by the fitted or predicted values. Within this plot, the range of residuals should be similar across the range of fitted or predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gf_point(.resid ~ .fitted, data = resid_diagnostics, size = 5, alpha = .15) |>\n",
    "  gf_smooth(method = 'loess', size = 2) |>\n",
    "  gf_labs(x = 'Fitted Values',\n",
    "          y = 'Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "gf_point(.std.resid ~ .fitted, data = resid_diagnostics, size = 5, alpha = .15) |>\n",
    "  gf_smooth(method = 'loess', size = 2) |>\n",
    "  gf_labs(x = 'Fitted Values',\n",
    "          y = 'Standardized Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another figure that can also be helpful for the homogeneity of variance assumption is one that rescales the residuals on the y-axis. The rescaling makes all the standardized residuals positive (takes the absolute value) and then takes the square root of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "resid_diagnostics |>\n",
    "  mutate(sqrt_abs_sresid = sqrt(abs(.std.resid))) |>\n",
    "  gf_point(sqrt_abs_sresid ~ .fitted, size = 5, alpha = .15) |>\n",
    "  gf_smooth(method = 'loess', size = 2) |>\n",
    "  gf_labs(x = 'Fitted Values',\n",
    "          y = 'Sqrt Abs Standardized Residuals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical test for homogeneity of variance\n",
    "\n",
    "There are also statistical tests that can aid in the assessing if the data are constant or not. The one that has been shown to perform relatively well is the Breusch-Pagan test. The details of the statistical test are not going to be discussed here, but we will focus on interpreting the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"car\")\n",
    "library(car)\n",
    "\n",
    "air_lm <- lm(daily_aqi ~ avg_wind, data = airquality)\n",
    "\n",
    "ncvTest(air_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data with high leverage\n",
    "\n",
    "Data with high leverage are extreme values that may significantly impact the regression estimates. These statistics include extreme values for the outcome or predictor attributes. Cook's distance is one statistic that can help to identify points with high impact/leverage for the regression estimates. Cook's distance is a statistic that represents how much change there would be in the fitted values if the point was removed when estimating the regression coefficients. There is some disagreement between what type of thresholds to use for Cook's distance, but one rule of thumb is Cook's distance greater than 1. There has also been some research showing that Cook's distance follows an F-distribution, so a more specific value could be computed. The rule of thumb for greater than 1 comes from the F distribution for large samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "resid_diagnostics |>\n",
    "  mutate(obs_num = 1:n()) |>\n",
    "  gf_col(.cooksd ~ obs_num, fill = 'black', color = 'black') |>\n",
    "  gf_labs(x = \"Observation Number\",\n",
    "          y = \"Cook's Distance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another leave one out statistic is the studentized deleted residuals. These are computed by removing a data point, refitting the regression model, then generate a predicted value for the X value for the data point removed. Then the residual is computed the same as before and is standardized like the standardized residuals above. The function in R to compute these is `rstudent()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(rstudent(air_lm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "airquality$student_residuals <- rstudent(air_lm)\n",
    "head(airquality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "airquality |>\n",
    "  mutate(obs_num = 1:n()) |>\n",
    "  gf_point(student_residuals ~ obs_num, size = 5, alpha = .15) |>\n",
    "  gf_hline(yintercept = ~ 3, color = 'blue', size = 2) |>\n",
    "  gf_labs(x = \"Observation Number\",\n",
    "          y = \"Studentized Residuals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leverage can be another measure to help detect outliers in X values. The hat values that were computed from the `augment()` function above and can be interpreted as the distance the X scores are from the center of all X predictors. In the case of a single predictor, the hat values are the distance the X score is from the mean of X. The hat values will also sum up to the number of predictors and will always range between 0 and 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "resid_diagnostics |>\n",
    "  mutate(obs_num = 1:n()) |>\n",
    "  gf_col(.hat ~ obs_num, fill = 'black', color = 'black') |>\n",
    "  gf_labs(x = \"Observation Number\",\n",
    "          y = \"Hat Values (leverage)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "plot(air_lm, which = 1:5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions to overcome data conditions not being met\n",
    "\n",
    "There are some strategies that can be done when a variety of data conditions for linear regression have not been met. In general, the strategies stem around generalizing the model and adding some complexity. \n",
    "\n",
    "The following are options that would be possible:\n",
    "\n",
    "1. Add interactions or other non-linear terms\n",
    "2. Use more complicated model \n",
    "    + weighted least squares for homogeneity of variance concerns\n",
    "    + models that include measurement error\n",
    "    + mixed models for correlated data\n",
    "3. Transform the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
