{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inference for regression parameters\n",
    "\n",
    "It is often of interest to perform inference about the regression parameters that we have estimated thus far. The reason inference is useful is based on the idea that for most problems the sample is used to approximate the population. Therefore, a subset of the population (the sample) is used to estimate the population parameters that are of most interest. As such, our estimates come with error and this uncertainty we can quantify when making inference about the parameter estimates. \n",
    "\n",
    "In this course, I plan to show you two ways to perform this inference. One of those frameworks will be the classical approach which uses classical statistical theory to estimate the amount of uncertainty in the parameter estimates. The second approach will use the bootstrap as a way to computationally estimate the uncertainty. The benefit of the bootstrap is that it comes with fewer assumptions than the classical approach. We will build up to these arguments. \n",
    "\n",
    "## Classical Inferential Framework\n",
    "\n",
    "The classical inferential framework, sometimes referred to as the null hypothesis significance test (NHST) has been around for more than 100 years. This framework builds off of the idea of a null hypothesis. \n",
    "\n",
    "A null hypothesis is typically thought as a hypothesis that assumes there is no relationship or a null effect. Framing this in the regression concept that we have been working with, we could define the following null hypotheses. \n",
    "\n",
    "$$\n",
    "H_{0}: \\beta_{0} = 0.\\ The\\  population\\  yintercept\\  equals\\  0.\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$ \n",
    "H_{0}: \\beta_{1} = 0.\\ The\\  population\\  slope\\  equals\\  0.\n",
    "$$\n",
    "\n",
    "In the following two null hypotheses, represented with $H_{0}$, the population parameters are being assumed to be 0 in the population. This is one definition of a null effect, but is not the only null effect we can define (more on this later). The value defined as a null effect is important as it centers the sampling distribution used for evaluating where the sample estimate falls in that distribution. \n",
    "\n",
    "Another hypothesis is typically defined with the null hypothesis, called the alternative hypothesis. This hypothesis states that there is an effect. Within the linear regression framework, we could write the alternative hypotheses as:\n",
    "\n",
    "$$ \n",
    "H_{A}: \\beta_{0} \\neq 0.\\ The\\  population\\  yintercept\\  is\\  not\\  equal\\  to\\  0.\n",
    "$$\n",
    "\n",
    "or \n",
    "\n",
    "$$ \n",
    "H_{A}: \\beta_{1} \\neq 0.\\ The\\  population\\  slope\\  is\\  not\\  equal\\  to\\  0. \n",
    "$$\n",
    "\n",
    "In the following two alternative hypotheses, represented with $H_{A}$, the population parameters are assumed to be not equal to 0. These can also be one-sided, more on this with an example later. \n",
    "\n",
    "### Estimating uncertainty in parameter estimates\n",
    "The standard error is used to estimate uncertainty or error in the parameter estimates due to having a sample from the population. More specifically, this means that the entire population is not used to estimate the parameter, therefore the estimate we have is very likely not equal exactly to the parameter. Instead, there is some sort of sampling error involved that we want to quantify. If the sample was collected well, ideally randomly, then the estimate should be unbiased. Unbiased here doesn't mean that the estimate equals the population parameter, rather, that through repeated sampling, the average of our sample estimates would equal the population parameter. \n",
    "\n",
    "As mentioned, standard errors are used to quantify this uncertainty. In the linear regression case we have explored so far, there are mathematical formula for the standard errors. These are shown below. \n",
    "\n",
    "$$\n",
    "SE\\left( \\hat{\\beta}_{0} \\right)^2 = \\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar{X}^2}{\\sum \\left( X - \\bar{X} \\right)^2} \\right)\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "SE\\left( \\hat{\\beta}_{1} \\right)^2 = \\frac{\\sigma^2}{\\sum \\left( X - \\bar{X} \\right)^2}\n",
    "$$"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "R"
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R",
   "language": "R"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}